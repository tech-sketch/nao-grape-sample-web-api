<?xml version="1.0" encoding="UTF-8" ?>
<ChoregrapheProject xmlns="http://www.aldebaran-robotics.com/schema/choregraphe/project.xsd" xar_version="3">
    <Box name="root" id="-1" localization="8" tooltip="Root box of Choregraphe&apos;s behavior. Highest level possible." x="0" y="0">
        <bitmap>media/images/box/root.png</bitmap>
        <script language="4">
            <content>
                <![CDATA[]]>
</content>
        </script>
        <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
        <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
        <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
        <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="ボックス動作の終了時に信号を送る。" id="4" />
        <Timeline enable="0">
            <BehaviorLayer name="behavior_layer1">
                <BehaviorKeyframe name="keyframe1" index="1">
                    <Diagram>
                        <Box name="Set Language" id="2" localization="8" tooltip="Select the language you would like the robot to speak and understand. Any following call to&#x0A;ALSpeechRecognition (Speech Reco. box for instance) or ALTextToSpeech (Say box&#x0A;for instance) will use this language." x="136" y="57">
                            <bitmap>media/images/box/interaction/say.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        try:
            self.tts = ALProxy("ALTextToSpeech")
        except:
            self.logger.warn("ALTextToSpeech is not available, language setting cannot be applied to speech")
            self.tts = None

        try:
            self.asr = ALProxy("ALSpeechRecognition")
        except:
            self.logger.warn("ALSpeechRecognition is not available, language setting cannot be applied to recognition")
            self.asr = None

        try:
            self.dialog = ALProxy("ALDialog")
        except:
            self.logger.warn("ALDialog is not available, language setting cannot be applied to dialog")
            self.dialog = None

    def onInput_onSet(self):
        lang = self.getParameter("Language")
        try:
            if self.asr:
                self.asr.setLanguage( self.getParameter("Language") )
            if self.tts:
                self.tts.setLanguage( self.getParameter("Language") )
            if self.dialog:
                self.dialog.setLanguage( self.getParameter("Language") )
            if self.tts is None and self.asr is None and self.dialog is None:
                raise RuntimeError("Cannot set language: neither ALTextToSpeech nor ALSpeechRecognition nor ALDialog is available.")
            self.onReady()
        except:
            error = "Language " + lang + " cannot be set."
            self.logger.warn(error)
            self.onError(error)]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="onSet" type="1" type_size="1" nature="1" inner="0" tooltip="The data is set when a signal is received on this input." id="2" />
                            <Output name="onReady" type="1" type_size="1" nature="2" inner="0" tooltip="Signal sent when the data has been set." id="3" />
                            <Output name="onError" type="3" type_size="1" nature="2" inner="0" tooltip="Error output:&#x0A;- triggered if the language asked cannot be set" id="4" />
                            <Parameter name="Language" inherits_from_parent="0" content_type="3" value="English" default_value="English" custom_choice="1" tooltip="Set the language the robot speaks and understands." id="5">
                                <Choice value="Arabic" />
                                <Choice value="Brazilian" />
                                <Choice value="Chinese" />
                                <Choice value="Czech" />
                                <Choice value="Danish" />
                                <Choice value="Dutch" />
                                <Choice value="English" />
                                <Choice value="Finnish" />
                                <Choice value="French" />
                                <Choice value="German" />
                                <Choice value="Greek" />
                                <Choice value="Italian" />
                                <Choice value="Japanese" />
                                <Choice value="Korean" />
                                <Choice value="Norwegian" />
                                <Choice value="Polish" />
                                <Choice value="Portuguese" />
                                <Choice value="Russian" />
                                <Choice value="Spanish" />
                                <Choice value="Swedish" />
                                <Choice value="Turkish" />
                            </Parameter>
                            <Resource name="Speech" type="Lock" timeout="0" />
                        </Box>
                        <Box name="Say" id="1" localization="8" tooltip="Say some text. Note that you must open the box to enter the text." x="331" y="58">
                            <bitmap>media/images/box/interaction/say.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        self.bIsRunning = False

    def onUnload(self):
        self.bIsRunning = False

    def onInput_onStart(self):
        self.bIsRunning = True

    def onInput_onStop(self):
        if( self.bIsRunning ):
            self.onUnload()
            self.onStopped()]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
                            <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this Input." id="2" />
                            <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this Input." id="3" />
                            <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished or stopped." id="4" />
                            <Parameter name="Voice shaping (%)" inherits_from_parent="0" content_type="1" value="100" default_value="100" min="50" max="150" tooltip='Used to modify at runtime the voice feature (tone, speed). In a slighty&#x0A;different way than pitch and speed, it gives a kind of &quot;gender or age&#x0A;modification&quot; effect.&#x0A;&#x0A;For instance, a quite good male derivation of female voice can be&#x0A;obtained setting this parameter to 78%.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the&#x0A;speed parameter. For example, if you want to decrease by 20% the voice&#x0A;shaping, you will have to increase by 20% the speed to keep a constant&#x0A;average speed.&#x0A;&#x0A;!Warning! This feature is not available yet in Japanese, Chinese and Korean.' id="5" />
                            <Parameter name="Speed (%)" inherits_from_parent="0" content_type="1" value="100" default_value="100" min="50" max="200" tooltip="Changes the speed of the voice.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the voice&#x0A;shaping parameter. For example, if you want to increase by 20% the speed, you&#x0A;will have to decrease by 20% the voice shaping to keep a constant average&#x0A;speed.&#x0A;&#x0A;!Warning! This feature is not available yet in Japanese, Chinese and Korean." id="6" />
                            <Timeline enable="0">
                                <BehaviorLayer name="behavior_layer1">
                                    <BehaviorKeyframe name="keyframe1" index="1">
                                        <Diagram>
                                            <Box name="Say Text" id="2" localization="8" tooltip="Say the text received on its input." x="422" y="65">
                                                <bitmap>media/images/box/interaction/say.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[import time

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)
        self.tts = ALProxy('ALTextToSpeech')
        self.ttsStop = ALProxy('ALTextToSpeech', True) #Create another proxy as wait is blocking if audioout is remote

    def onLoad(self):
        self.bIsRunning = False
        self.ids = []

    def onUnload(self):
        for id in self.ids:
            try:
                self.ttsStop.stop(id)
            except:
                pass
        while( self.bIsRunning ):
            time.sleep( 0.2 )

    def onInput_onStart(self, p):
        self.bIsRunning = True
        try:
            sentence = "\RSPD="+ str( self.getParameter("Speed (%)") ) + "\ "
            sentence += "\VCT="+ str( self.getParameter("Voice shaping (%)") ) + "\ "
            sentence += str(p)
            sentence +=  "\RST\ "
            id = self.tts.post.say(str(sentence))
            self.ids.append(id)
            self.tts.wait(id, 0)
        finally:
            try:
                self.ids.remove(id)
            except:
                pass
            if( self.ids == [] ):
                self.onStopped() # activate output of the box
                self.bIsRunning = False

    def onInput_onStop(self):
        self.onUnload()]]>
</content>
                                                </script>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
                                                <Input name="onStart" type="3" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this Input." id="2" />
                                                <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this Input." id="3" />
                                                <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when Box behavior is finished." id="4" />
                                                <Parameter name="Voice shaping (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="150" tooltip='Used to modify at runtime the voice feature (tone, speed). In a slighty&#x0A;different way than pitch and speed, it gives a kind of &quot;gender or age&#x0A;modification&quot; effect.&#x0A;&#x0A;For instance, a quite good male derivation of female voice can be&#x0A;obtained setting this parameter to 78%.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the&#x0A;speed parameter. For example, if you want to decrease by 20% the voice&#x0A;shaping, you will have to increase by 20% the speed to keep a constant&#x0A;average speed.' id="5" />
                                                <Parameter name="Speed (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="200" tooltip="Changes the speed of the voice.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the voice&#x0A;shaping parameter. For example, if you want to increase by 20% the speed, you&#x0A;will have to decrease by 20% the voice shaping to keep a constant average&#x0A;speed." id="6" />
                                            </Box>
                                            <Box name="Localized Text" id="5" localization="8" tooltip="Send on the output the text associated with the robot&apos;s current voice language.&#x0A;You can display and edit the text associated with any language by&#x0A;selecting the language in the combobox.&#x0A;&#x0A;!!Warning!! The text sent on the output is NOT the displayed one but the one&#x0A;associated with the robot&apos;s current voice language." plugin="localizationbox_plugin" x="114" y="68">
                                                <bitmap>media/images/box/interaction/vocabulary.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[# /!\ Generated content. Do not edit!
class MyClass(GeneratedClass):
	def __init__(self):
		try: # disable autoBind
			GeneratedClass.__init__(self, False)
		except TypeError: # if NAOqi < 1.14
			GeneratedClass.__init__( self )

		self.tts = ALProxy("ALTextToSpeech")
		self.sentences = {
			"Arabic" : "  ",
			"Czech" : " Ahoj ",
			"Danish" : " Hej ",
			"German" : " Hallo ",
			"Greek" : "  ",
			"English" : " What\'s your name? ",
			"Spanish" : " Hola ",
			"Finnish" : " Hei ",
			"French" : " Bonjour ",
			"Italian" : " Ciao ",
			"Japanese" : " こんにちは ",
			"Korean" : " 안녕하세요 ",
			"Dutch" : " Hallo ",
			"Norwegian" : "  ",
			"Polish" : " Cześć ",
			"Brazilian" : " Olá ",
			"Portuguese" : " Olá ",
			"Russian" : " Привет ",
			"Swedish" : " Hallå ",
			"Turkish" : " Merhaba ",
			"Chinese" : "  "
		}

	def onInput_onStart(self):
		sDefaultLang = self.tts.getLanguage()
		self.onStopped(self.sentences[sDefaultLang])]]>
</content>
                                                </script>
                                                <pluginContent>
                                                    <arabic>
                                                        <![CDATA[]]>
</arabic>
                                                    <czech>
                                                        <![CDATA[Ahoj]]>
</czech>
                                                    <danish>
                                                        <![CDATA[Hej]]>
</danish>
                                                    <german>
                                                        <![CDATA[Hallo]]>
</german>
                                                    <greek>
                                                        <![CDATA[]]>
</greek>
                                                    <english>
                                                        <![CDATA[What's your name?]]>
</english>
                                                    <spanish>
                                                        <![CDATA[Hola]]>
</spanish>
                                                    <finnish>
                                                        <![CDATA[Hei]]>
</finnish>
                                                    <french>
                                                        <![CDATA[Bonjour]]>
</french>
                                                    <italian>
                                                        <![CDATA[Ciao]]>
</italian>
                                                    <japanese>
                                                        <![CDATA[こんにちは]]>
</japanese>
                                                    <korean>
                                                        <![CDATA[안녕하세요]]>
</korean>
                                                    <dutch>
                                                        <![CDATA[Hallo]]>
</dutch>
                                                    <norwegian>
                                                        <![CDATA[]]>
</norwegian>
                                                    <polish>
                                                        <![CDATA[Cześć]]>
</polish>
                                                    <brazilian>
                                                        <![CDATA[Olá]]>
</brazilian>
                                                    <portuguese>
                                                        <![CDATA[Olá]]>
</portuguese>
                                                    <russian>
                                                        <![CDATA[Привет]]>
</russian>
                                                    <swedish>
                                                        <![CDATA[Hallå]]>
</swedish>
                                                    <turkish>
                                                        <![CDATA[Merhaba]]>
</turkish>
                                                    <chinese>
                                                        <![CDATA[]]>
</chinese>
                                                    <language>7</language>
                                                </pluginContent>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Data is sent on the output when this input is stimulated." id="2" />
                                                <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="Data sent when asked." id="3" />
                                            </Box>
                                            <Link inputowner="0" indexofinput="4" outputowner="2" indexofoutput="4" />
                                            <Link inputowner="5" indexofinput="2" outputowner="0" indexofoutput="2" />
                                            <Link inputowner="2" indexofinput="2" outputowner="5" indexofoutput="3" />
                                        </Diagram>
                                    </BehaviorKeyframe>
                                </BehaviorLayer>
                            </Timeline>
                            <Resource name="Speech" type="Lock" timeout="0" />
                        </Box>
                        <Box name="HTTP Google STT" id="4" localization="8" tooltip="This box contains a basic python script and can be used to create any python script box you would like.&#x0A;&#x0A;To edit its script, double-click on it." x="337" y="239">
                            <bitmap>media/images/box/box-python-script.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self)

    def onLoad(self):
        #put initialization code here
        pass

    def onUnload(self):
        #put clean-up code here
        pass

    def onInput_onStart(self, p):
        self.logger.info(p)
        filepath = p

        import os
        import json
        import requests
        import urllib

        try:
            timeout = int(self.getParameter("Timeout"))

            q = {"output": "json",
                 "lang": self.getParameter("Lang"),
                 "key": self.getParameter("GOOGLE_API_KEY")}

            url = "http://www.google.com/speech-api/v2/recognize?%s" % (urllib.urlencode(q))

            self.logger.info(url)

            headers = {"Content-Type": "audio/l16; rate=16000"}
            data = open(filepath, "rb").read()

            response = requests.post(
                url,
                headers=headers,
                data=data,
                timeout=timeout
            )

            jsonunits = response.text.split(os.linesep)
            res = ""

            for unit in jsonunits:
                if not unit:
                    continue
                obj = json.loads(unit)
                alternatives = obj["result"]

                if len(alternatives) > 0:
                    breakflag = False
                    for obj in alternatives:
                        results = obj["alternative"]
                        for result in results:
                            res = result["transcript"]
                            breakflag = True
                            break

                        if breakflag:
                            break

            text = res.encode("UTF-8")
            self.logger.info("result: %s" % text)

            self.onStopped(text)

        except requests.exceptions.RequestException, message:
            self.logger.warn("Failed to open: message=%s" % (message))
            self.onFailed(message)

    def onInput_onStop(self):
        self.onUnload() #it is recommended to reuse the clean-up as the box is stopped
        self.onStopped(p) #activate the output of the box]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="onStart" type="3" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
                            <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
                            <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="4" />
                            <Output name="onFailed" type="3" type_size="1" nature="1" inner="0" tooltip="" id="5" />
                            <Parameter name="GOOGLE_API_KEY" inherits_from_parent="0" content_type="3" value="YOUR_API_KEY" default_value="" custom_choice="0" tooltip="" id="6" />
                            <Parameter name="Lang" inherits_from_parent="0" content_type="3" value="en-US" default_value="en-US" custom_choice="0" tooltip="" id="7" />
                            <Parameter name="Timeout" inherits_from_parent="0" content_type="1" value="10" default_value="10" min="1" max="100" tooltip="" id="8" />
                        </Box>
                        <Box name="Get Name" id="5" localization="8" tooltip="" x="540" y="243">
                            <bitmap>media/images/box/box-python-script.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[class MyClass(GeneratedClass):

    def __init__(self):
        GeneratedClass.__init__(self)

    def onLoad(self):
        #put initialization code here
        self.memory = ALProxy("ALMemory")

    def onUnload(self):
        #put clean-up code here
        self.memory = None

    def onInput_onStart(self, p):
        import re

        name = re.sub(r'I am', '', p)

        self.logger.info(name)

        self.memory.insertData("pepper_google_stt_username", name)

        if name is None or name == "":
            message = "It is fine today."
        else:
            message = "Hi, " + name

        self.onStopped(message)

    def onInput_onStop(self):
        self.onUnload() #it is recommended to reuse the clean-up as the box is stopped
        self.onStopped(p) #activate the output of the box]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="onStart" type="3" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
                            <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
                            <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="4" />
                        </Box>
                        <Box name="Say Text" id="6" localization="8" tooltip="Say the text received on its input." x="718" y="244">
                            <bitmap>media/images/box/interaction/say.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[import time

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)
        self.tts = ALProxy('ALTextToSpeech')
        self.ttsStop = ALProxy('ALTextToSpeech', True) #Create another proxy as wait is blocking if audioout is remote

    def onLoad(self):
        self.bIsRunning = False
        self.ids = []

    def onUnload(self):
        for id in self.ids:
            try:
                self.ttsStop.stop(id)
            except:
                pass
        while( self.bIsRunning ):
            time.sleep( 0.2 )

    def onInput_onStart(self, p):
        self.bIsRunning = True
        try:
            sentence = "\RSPD="+ str( self.getParameter("Speed (%)") ) + "\ "
            sentence += "\VCT="+ str( self.getParameter("Voice shaping (%)") ) + "\ "
            sentence += str(p)
            sentence +=  "\RST\ "
            id = self.tts.post.say(str(sentence))
            self.ids.append(id)
            self.tts.wait(id, 0)
        finally:
            try:
                self.ids.remove(id)
            except:
                pass
            if( self.ids == [] ):
                self.onStopped() # activate output of the box
                self.bIsRunning = False

    def onInput_onStop(self):
        self.onUnload()]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
                            <Input name="onStart" type="3" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this Input." id="2" />
                            <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this Input." id="3" />
                            <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when Box behavior is finished." id="4" />
                            <Parameter name="Voice shaping (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="150" tooltip='Used to modify at runtime the voice feature (tone, speed). In a slighty&#x0A;different way than pitch and speed, it gives a kind of &quot;gender or age&#x0A;modification&quot; effect.&#x0A;&#x0A;For instance, a quite good male derivation of female voice can be&#x0A;obtained setting this parameter to 78%.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the&#x0A;speed parameter. For example, if you want to decrease by 20% the voice&#x0A;shaping, you will have to increase by 20% the speed to keep a constant&#x0A;average speed.' id="5" />
                            <Parameter name="Speed (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="200" tooltip="Changes the speed of the voice.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the voice&#x0A;shaping parameter. For example, if you want to increase by 20% the speed, you&#x0A;will have to decrease by 20% the voice shaping to keep a constant average&#x0A;speed." id="6" />
                            <Resource name="Speech" type="Lock" timeout="0" />
                        </Box>
                        <Box name="Record Sound for Google STT (1)" id="7" localization="8" tooltip='Record a sound on the robot. You can choose to record only with one&#x0A;microphone (the front head microphone) in ogg format, or with four microphones&#x0A;(front, sides and rear head microphones) in wav format.&#x0A;&#x0A;If &quot;Temporary storage&quot; isn&apos;t checked, the output sound file is located in &quot;~/recordings/microphones/&lt;File name&gt;&quot;.&#x0A;Else, it is located in a temporary directory&#x0A;&#x0A;The onStopped output is stimulated at the end of the recording and contains the absolute path to the output sound file&#x0A;&#x0A;V1.1.0&#x0A;' x="146" y="241">
                            <bitmap>media/images/box/interaction/rec_sound.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Launches the recording of the sound." id="2" />
                            <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Stops the recording of the sound." id="3" />
                            <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="Returns the absolute path of the output sound file at the end of the recording" id="4" />
                            <Parameter name="File name" inherits_from_parent="0" content_type="3" value="recording" default_value="recording" custom_choice="0" tooltip="Name of the destination file without its extension." id="5" />
                            <Parameter name="Microphones used" inherits_from_parent="0" content_type="3" value="Front, sides and rear head microphones (.wav)" default_value="Front, sides and rear head microphones (.wav)" custom_choice="0" tooltip="Microphones used to record the sound.&#x0A;&#x0A;Note: If you use only the front head microphone the file will be saved in ogg format. If you use the&#x0A;front, sides and rear head microphones it will be saved in wav format." id="6">
                                <Choice value="Front head microphone only (.ogg)" />
                                <Choice value="Front, sides and rear head microphones (.wav)" />
                            </Parameter>
                            <Parameter name="Temporary storage" inherits_from_parent="0" content_type="0" value="1" default_value="1" tooltip="Choose if the file should be stored as a temporary file so it is removed as soon&#x0A;as the behavior is unloaded.&#x0A;&#x0A;When this option is disabled the file is stored in ~/recordings/microphones. You can&#x0A;then get it on your computer using the menu Connection/File transfer.&#x0A;&#x0A;When this option is enabled the file is stored in the temporary folder of the behavior." id="7" />
                            <Parameter name="Timeout (s)" inherits_from_parent="0" content_type="2" value="5" default_value="5" min="0.1" max="60" tooltip="Duration of the recording in seconds." id="8" />
                            <Timeline enable="0">
                                <BehaviorLayer name="behavior_layer1">
                                    <BehaviorKeyframe name="keyframe1" index="1">
                                        <Diagram>
                                            <Box name="Rec. Sound File" id="4" localization="8" tooltip="Record a sound on the robot. You can choose to record only with one&#x0A;microphone (the front head microphone) in ogg format, or with four microphones&#x0A;(front, sides and rear head&#x0A;microphones) in wav format." x="562" y="100">
                                                <bitmap>media/images/box/interaction/rec_sound.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)
        try:
            #self.ad = ALProxy("ALAudioDevice")
            self.audioRecorder = ALProxy("ALAudioRecorder")
        except Exception as e:
            #self.ad = None
            self.audioRecorder = None
            self.logger.error(e)
        self.filepath = ""

    def onLoad(self):
        self.bIsRecording = False
        self.bIsRunning = False

    def onUnload(self):
        self.bIsRunning = False
        if( self.bIsRecording ):
            #self.ad.stopMicrophonesRecording()
            self.audioRecorder.stopMicrophonesRecording()
            self.bIsRecording = False

    def onInput_onStart(self, p):
        if(self.bIsRunning):
            return
        self.bIsRunning = True
        sExtension = self.toExtension( self.getParameter("Microphones used") )
        self.filepath = p + sExtension
        #if self.ad:
        if self.audioRecorder:
            channels = [0, 0, 1, 0]
            self.audioRecorder.startMicrophonesRecording(self.filepath, "wav", 16000, channels)
            #self.ad.startMicrophonesRecording( self.filepath )
            self.bIsRecording = True
        else:
            self.logger.warning("No sound recorded")

    def onInput_onStop(self):
        if( self.bIsRunning ):
            self.onUnload()
            self.onStopped(self.filepath)

    def toExtension(self, sMicrophones):
        if( sMicrophones == "Front head microphone only (.ogg)" ):
            return ".ogg"
        else:
            return ".wav"]]>
</content>
                                                </script>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                <Input name="onStart" type="3" type_size="1" nature="2" inner="0" tooltip="Launches the recording of the sound. The data received on this input must be the&#x0A;filename of the sound." id="2" />
                                                <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Stops the recording of the sound." id="3" />
                                                <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="Returns the absolute path of the output sound file at the end of the recording" id="4" />
                                                <Parameter name="Microphones used" inherits_from_parent="1" content_type="3" value="Front, sides and rear head microphones (.wav)" default_value="Front, sides and rear head microphones (.wav)" custom_choice="0" tooltip="Microphones used to record the sound.&#x0A;&#x0A;Note: If you use only the front head microphone the file will be saved in ogg format. If you use the&#x0A;front, sides and rear head microphones it will be saved in wav format." id="5">
                                                    <Choice value="Front head microphone only (.ogg)" />
                                                    <Choice value="Front, sides and rear head microphones (.wav)" />
                                                </Parameter>
                                            </Box>
                                            <Box name="Wait" id="13" localization="8" tooltip="Wait a moment before sending a bang on the output. The wait can be stopped any&#x0A;time. You may restart it any time, and it will start over." x="420" y="161">
                                                <bitmap>media/images/box/wait.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[import threading # opkg install python-threading
class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        self.tb = False

    def onUnload(self):
        if( self.tb ):
            self.tb.cancel()
            self.tb = False

    def triggerOutput( self, rPeriod = 1 ):
        self.onUnload() # to clean everything
        self.timerOutput()

    def startTimer( self, rPeriod = 1 ):
        if( self.tb ):
            self.tb.cancel()
        self.tb = threading.Timer( rPeriod, self.triggerOutput, [rPeriod] )
        self.tb.start()

    def onInput_onStart(self):
        self.startTimer( self.getParameter("Timeout (s)") )

    def onInput_onStop(self):
        bRunning = self.tb
        self.onUnload()
        if( bRunning ):
            self.timerOutput()]]>
</content>
                                                </script>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Start the Wait box with the configured timeout value." id="2" />
                                                <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Stop the wait and stimulate the output." id="3" />
                                                <Output name="timerOutput" type="1" type_size="1" nature="1" inner="0" tooltip="Send a bang once time set in parameters is ellapsed, or if the box is stopped." id="4" />
                                                <Parameter name="Timeout (s)" inherits_from_parent="1" content_type="2" value="5" default_value="1" min="0" max="5000" tooltip="Duration the box waits before stimulating the output." id="5" />
                                            </Box>
                                            <Box name="Get File Name" id="10" localization="8" tooltip="Use this box to choose an attached file in its parameters. The filename will be sent on&#x0A;the output when the input is stimulated." x="234" y="95">
                                                <bitmap>media/images/box/folder.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[import os
class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        self.framemanager = ALProxy("ALFrameManager")

    def onInput_onStart(self):
        if( self.getParameter("Temporary storage") ):
            import tempfile
            path = tempfile.mkdtemp() + "/"
        else:
            path = os.path.expanduser('~') + "/recordings/microphones/"
        self.onStopped( path + self.getParameter("File name") )]]>
</content>
                                                </script>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                <Input name="onStart" type="1" type_size="1" nature="1" inner="0" tooltip="To send the filepath on the output." id="2" />
                                                <Output name="onStopped" type="3" type_size="1" nature="2" inner="0" tooltip="The filepath of the selected resource file." id="3" />
                                                <Parameter name="File name" inherits_from_parent="1" content_type="3" value="recording" default_value="" custom_choice="0" tooltip="Name of the file." id="4" />
                                                <Parameter name="Temporary storage" inherits_from_parent="1" content_type="0" value="1" default_value="1" tooltip="Choose if the file should be stored as a temporary file so it is removed as soon&#x0A;as the behavior is unloaded.&#x0A;&#x0A;When this option is enabled the file is stored in ~/.cache/currentChoregrapheBehavior&#x0A;or in ~/.cache/&lt;project_name&gt; when you play the behavior from the&#x0A;behavior manager.&#x0A;&#x0A;When it is disabled the file is stored in ~/recordedSounds. You can&#x0A;then get it on your computer using the menu Connection/File transfer." id="5" />
                                            </Box>
                                            <Link inputowner="0" indexofinput="4" outputowner="4" indexofoutput="4" />
                                            <Link inputowner="4" indexofinput="3" outputowner="13" indexofoutput="4" />
                                            <Link inputowner="10" indexofinput="2" outputowner="0" indexofoutput="2" />
                                            <Link inputowner="13" indexofinput="2" outputowner="10" indexofoutput="3" />
                                            <Link inputowner="4" indexofinput="2" outputowner="10" indexofoutput="3" />
                                        </Diagram>
                                    </BehaviorKeyframe>
                                </BehaviorLayer>
                            </Timeline>
                            <Resource name="Audio recorder" type="Lock" timeout="0" />
                        </Box>
                        <Link inputowner="2" indexofinput="2" outputowner="0" indexofoutput="2" />
                        <Link inputowner="1" indexofinput="2" outputowner="2" indexofoutput="3" />
                        <Link inputowner="5" indexofinput="2" outputowner="4" indexofoutput="4" />
                        <Link inputowner="6" indexofinput="2" outputowner="5" indexofoutput="4" />
                        <Link inputowner="7" indexofinput="2" outputowner="1" indexofoutput="4" />
                        <Link inputowner="4" indexofinput="2" outputowner="7" indexofoutput="4" />
                    </Diagram>
                </BehaviorKeyframe>
            </BehaviorLayer>
        </Timeline>
    </Box>
</ChoregrapheProject>
